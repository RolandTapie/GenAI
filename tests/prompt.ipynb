{
 "cells": [
  {
   "cell_type": "code",
   "id": "45fe20c17cacd004",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T05:39:11.591448Z",
     "start_time": "2025-09-02T05:39:05.957114Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "import os\n",
    "from src.services.llm_generation.llm import Prompt, Model\n",
    "from src.services.tools.News.news import API_KEY\n",
    "from src.services.tools.agent_tools import AgentTools\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"openai_key\")\n",
    "gemini_api_key = os.getenv(\"gemini_key\")\n",
    "claude_api_key = os.getenv(\"claude_key\")\n",
    "tools_path = os.getenv(\"tools\")\n",
    "\n",
    "gemini_model=\"gemini-2.5-flash\"\n",
    "llm_model=gemini_model\n",
    "gemini_key=gemini_api_key\n",
    "api_key = gemini_key\n",
    "gemini_base_url= \"https://generativelanguage.googleapis.com/v1beta\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model=OpenAI(api_key=gemini_key,base_url=gemini_base_url)\n",
    "tools_openai, tools_gemini = AgentTools().list_of_tools(tools_path)\n",
    "role=\"user\"\n",
    "context=\"\"\n",
    "source=\"\"\n",
    "message =\"quelle est la capitale de la Belgique?\"\n",
    "prompt=Prompt(role,context,source,message)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tallar\\Documents\\PROJETS\\GenAI\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T05:39:11.617549Z",
     "start_time": "2025-09-02T05:39:11.612781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(tools_gemini)\n",
    " # récupère la clé depuis GEMINI_API_KEY ou GOOGLE_API_KEY\n"
   ],
   "id": "22f7d2ea093b7893",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'function_declarations': [{'name': 'list_of_tools', 'description': 'No description available.', 'parameters': {'type': 'object', 'properties': {'self': {'type': 'string', 'description': 'Paramètre self'}, 'racine': {'type': 'string', 'description': 'Paramètre racine'}}, 'required': ['self', 'racine']}}]}, {'function_declarations': [{'name': 'f_get_bank_transaction', 'description': 'Permet de récupérer la liste des transactions bancaires\\nReturns:\\n     str: la liste des transactions bancaires.', 'parameters': {'type': 'object', 'properties': {}, 'required': []}}]}, {'function_declarations': [{'name': 'f_get_data', 'description': ':param id: identifiant du redevable\\n:return: la liste des créances ou des transactions encore ourvertes', 'parameters': {'type': 'object', 'properties': {'id': {'type': 'string', 'description': 'Paramètre id'}}, 'required': ['id']}}]}, {'function_declarations': [{'name': 'f_get_weather', 'description': \"Récupère la météo actuelle en fonction de la latitude et longitude via l'API Open-Meteo.\\n\\nArgs:\\n    latitude (float): Latitude de la position.\\n    longitude (float): Longitude de la position.\\n\\nReturns:\\n    str: Description simple de la météo (température, conditions).\", 'parameters': {'type': 'object', 'properties': {'latitude': {'type': 'string', 'description': 'Paramètre latitude'}, 'longitude': {'type': 'string', 'description': 'Paramètre longitude'}}, 'required': ['latitude', 'longitude']}}]}]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T05:39:12.357458Z",
     "start_time": "2025-09-02T05:39:12.320924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.5-flash\", # Replace with your actual key\n",
    "    tools=tools_gemini\n",
    ")\n",
    "# Generate content\n",
    "\n",
    "\n",
    "def gemini_process(model, agent, message):\n",
    "    response = model.generate_content(message)\n",
    "    tool_responses=[]\n",
    "    # Print the result\n",
    "    for part in response.candidates[0].content.parts:\n",
    "        # Vérifier si la partie est un appel de fonction\n",
    "        if hasattr(part, 'function_call'):\n",
    "            tool_call = part.function_call\n",
    "\n",
    "            # Obtenir le nom de la fonction et ses arguments\n",
    "            tool_name = tool_call.name\n",
    "            tool_args = tool_call.args\n",
    "\n",
    "            print(f\"Le modèle a demandé d'exécuter la fonction : {tool_name}\")\n",
    "            print(f\"Avec les arguments : {tool_args}\")\n",
    "            result = agent.use_tool(tool_name,tool_args)\n",
    "\n",
    "            tool_responses.append(result)\n",
    "\n",
    "    if tool_responses:\n",
    "        print(\"\\n-------------------------------------------------------------\")\n",
    "        print(\"Résultat des outils obtenu. On le renvoie au modèle...\")\n",
    "        print(\"-------------------------------------------------------------\")\n",
    "\n",
    "        # 1. Créez un objet de contenu pour le message initial de l'utilisateur\n",
    "        user_content = genai.protos.Content(\n",
    "            parts=[genai.protos.Part(text=message)],\n",
    "            role='user'\n",
    "        )\n",
    "\n",
    "        # 2. L'historique de la conversation commence par le message de l'utilisateur...\n",
    "        chat_history = [user_content]\n",
    "\n",
    "        # 3. ...suivi par la réponse du modèle qui contient l'appel de fonction...\n",
    "        chat_history.append(response.candidates[0].content)\n",
    "\n",
    "        # 4. ...suivi par la réponse de l'outil qui contient les résultats.\n",
    "        tool_content = genai.protos.Content(\n",
    "            parts=[genai.protos.Part(text=tool_responses[0])],\n",
    "            role='user'\n",
    "        )\n",
    "        chat_history.append(tool_content)\n",
    "\n",
    "        # Relancez generate_content avec l'historique complet pour obtenir la réponse finale\n",
    "        final_response = model.generate_content(chat_history)\n",
    "        print(\"\\n-------------------------------------------------------------\")\n",
    "        print(\"Réponse finale du modèle :\")\n",
    "        print(\"-------------------------------------------------------------\")\n",
    "        return final_response.text\n",
    "    else:\n",
    "        print(\"\\n-------------------------------------------------------------\")\n",
    "        print(\"Le modèle a fourni une réponse textuelle directe :\")\n",
    "        print(\"-------------------------------------------------------------\")\n",
    "        return response.text\n"
   ],
   "id": "69bb548e0084c780",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T05:39:25.279012Z",
     "start_time": "2025-09-02T05:39:20.069854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message =\"donne moi la liste des tes outils\"\n",
    "print(prompt.gemini_process(model, AgentTools(), message))"
   ],
   "id": "e865fbeaa8ab248a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle a demandé d'exécuter la fonction : \n",
      "Avec les arguments : None\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Résultat des outils obtenu. On le renvoie au modèle...\n",
      "-------------------------------------------------------------\n",
      "chat_history : [parts {\n",
      "  text: \"donne moi la liste des tes outils\"\n",
      "}\n",
      "role: \"user\"\n",
      ", parts {\n",
      "  function_call {\n",
      "    name: \"f_get_bank_transaction\"\n",
      "    args {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "role: \"model\"\n",
      ", parts {\n",
      "  text: \" l\\'outil de recherche  \"\n",
      "}\n",
      "role: \"user\"\n",
      "]\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Réponse finale du modèle :\n",
      "-------------------------------------------------------------\n",
      "Je n'ai pas d'outil de recherche général à proprement parler. Cependant, je peux :\n",
      "\n",
      "*   Récupérer la liste des transactions bancaires avec l'outil `f_get_bank_transaction`.\n",
      "*   Récupérer des données spécifiques (créances ou transactions ouvertes) avec l'outil `f_get_data` en fournissant un `id`.\n",
      "*   Récupérer la météo actuelle avec l'outil `f_get_weather` en fournissant une `latitude` et une `longitude`.\n",
      "\n",
      "Pourriez-vous me préciser ce que vous souhaitez rechercher ?\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.services.Agent.agent import Agent\n",
    "from src.services.llm_generation.llm import Model\n",
    "from src.services.tools.agent_tools import AgentTools\n",
    "from src.services.memory.agent_memory import AgentMemory"
   ],
   "id": "62b0db44f8f2a98e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T08:15:17.829144Z",
     "start_time": "2025-09-02T08:15:17.354223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "model=Model(\"openai\",\"gpt-4o\")\n",
    "agent=Agent(model=model,tools=AgentTools(),memory=AgentMemory())\n"
   ],
   "id": "1a0b819669450d0d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T08:19:29.529066Z",
     "start_time": "2025-09-02T08:19:22.362188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "agent.run(\"user\",\"\",\"peux tu me communiquer la liste de mes dernieres transactions bancaires?\")\n"
   ],
   "id": "bf92e6eac51c69df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appel de fonction 1\n",
      "ChatCompletionMessageToolCall(id='call_jPcfQLOpTpWymF4okGLH5sR3', function=Function(arguments='{}', name='f_get_bank_transaction'), type='function')\n",
      "call_id: call_jPcfQLOpTpWymF4okGLH5sR3\n",
      "name: f_get_bank_transaction\n",
      "arguments: {}\n",
      "----le prompt après appels des fonctions----\n",
      "[ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_jPcfQLOpTpWymF4okGLH5sR3', function=Function(arguments='{}', name='f_get_bank_transaction'), type='function')]), {'role': 'tool', 'tool_call_id': 'call_jPcfQLOpTpWymF4okGLH5sR3', 'content': '\"01/08/2025 Salaire \\\\u2013 Entreprise XYZ +2500,00 \\\\u20ac Solde : 2500,00 \\\\u20ac\\\\n        03/08/2025 Paiement carte \\\\u2013 Supermarch\\\\u00e9 -75,60 \\\\u20ac Solde : 2424,40 \\\\u20ac\\\\n        05/08/2025 Virement re\\\\u00e7u \\\\u2013 Amis +150,00 \\\\u20ac Solde : 2574,40 \\\\u20ac\\\\n        07/08/2025 Pr\\\\u00e9l\\\\u00e8vement automatique \\\\u2013 \\\\u00c9lectricit\\\\u00e9 -120,45 \\\\u20ac Solde : 2453,95 \\\\u20ac\\\\n        10/08/2025 Retrait DAB -200,00 \\\\u20ac Solde : 2253,95 \\\\u20ac\\\\n        12/08/2025 Paiement carte \\\\u2013 Restaurant -45,80 \\\\u20ac Solde : 2208,15 \\\\u20ac\\\\n        15/08/2025 Virement vers compte \\\\u00e9pargne -500,00 \\\\u20ac Solde : 1708,15 \\\\u20ac\\\\n        18/08/2025 Paiement carte \\\\u2013 Boutique en ligne -89,99 \\\\u20ac Solde : 1618,16 \\\\u20ac\\\\n        21/08/2025 Pr\\\\u00e9l\\\\u00e8vement automatique \\\\u2013 Internet -35,00 \\\\u20ac Solde : 1583,16 \\\\u20ac\\\\n        23/08/2025 Remboursement pr\\\\u00eat personnel +300,00 \\\\u20ac Solde : 1883,16 \\\\u20ac\"'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here is the list of recent bank transactions:\\n\\n1. **01/08/2025** - Salary from Company XYZ: **+2500,00 €**  \\n   Balance: **2500,00 €**\\n\\n2. **03/08/2025** - Card Payment at Supermarket: **-75,60 €**  \\n   Balance: **2424,40 €**\\n\\n3. **05/08/2025** - Received Transfer from Friends: **+150,00 €**  \\n   Balance: **2574,40 €**\\n\\n4. **07/08/2025** - Automatic Debit for Electricity: **-120,45 €**  \\n   Balance: **2453,95 €**\\n\\n5. **10/08/2025** - ATM Withdrawal: **-200,00 €**  \\n   Balance: **2253,95 €**\\n\\n6. **12/08/2025** - Card Payment at Restaurant: **-45,80 €**  \\n   Balance: **2208,15 €**\\n\\n7. **15/08/2025** - Transfer to Savings Account: **-500,00 €**  \\n   Balance: **1708,15 €**\\n\\n8. **18/08/2025** - Card Payment at Online Store: **-89,99 €**  \\n   Balance: **1618,16 €**\\n\\n9. **21/08/2025** - Automatic Debit for Internet: **-35,00 €**  \\n   Balance: **1583,16 €**\\n\\n10. **23/08/2025** - Personal Loan Repayment: **+300,00 €**  \\n    Balance: **1883,16 €**'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
