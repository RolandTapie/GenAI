{
 "cells": [
  {
   "cell_type": "code",
   "id": "45fe20c17cacd004",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T15:27:41.554794Z",
     "start_time": "2025-09-01T15:27:33.867132Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "import os\n",
    "from src.services.llm_generation.llm import Prompt\n",
    "from src.services.tools.News.news import API_KEY\n",
    "from src.services.tools.agent_tools import AgentTools\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"openai_key\")\n",
    "gemini_api_key = os.getenv(\"gemini_key\")\n",
    "claude_api_key = os.getenv(\"claude_key\")\n",
    "tools_path = os.getenv(\"tools\")\n",
    "\n",
    "gemini_model=\"gemini-2.5-flash\"\n",
    "llm_model=gemini_model\n",
    "gemini_key=gemini_api_key\n",
    "api_key = gemini_key\n",
    "gemini_base_url= \"https://generativelanguage.googleapis.com/v1beta\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model=OpenAI(api_key=gemini_key,base_url=gemini_base_url)\n",
    "tools_openai, tools_gemini = AgentTools().list_of_tools(tools_path)\n",
    "role=\"user\"\n",
    "context=\"\"\n",
    "source=\"\"\n",
    "message =\"quelle est la capitale de la Belgique?\"\n",
    "prompt=Prompt(role,context,source,message)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tallar\\Documents\\PROJETS\\GenAI\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T15:27:49.232497Z",
     "start_time": "2025-09-01T15:27:49.223491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(tools_gemini)\n",
    " # récupère la clé depuis GEMINI_API_KEY ou GOOGLE_API_KEY\n"
   ],
   "id": "22f7d2ea093b7893",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'function_declarations': [{'name': 'list_of_tools', 'description': 'No description available.', 'parameters': {'type': 'object', 'properties': {'self': {'type': 'string', 'description': 'Paramètre self'}, 'racine': {'type': 'string', 'description': 'Paramètre racine'}}, 'required': ['self', 'racine']}}]}, {'function_declarations': [{'name': 'f_get_data', 'description': ':param id: identifiant du redevable\\n:return: la liste des créances ou des transactions encore ourvertes', 'parameters': {'type': 'object', 'properties': {'id': {'type': 'string', 'description': 'Paramètre id'}}, 'required': ['id']}}]}, {'function_declarations': [{'name': 'f_get_weather', 'description': \"Récupère la météo actuelle en fonction de la latitude et longitude via l'API Open-Meteo.\\n\\nArgs:\\n    latitude (float): Latitude de la position.\\n    longitude (float): Longitude de la position.\\n\\nReturns:\\n    str: Description simple de la météo (température, conditions).\", 'parameters': {'type': 'object', 'properties': {'latitude': {'type': 'string', 'description': 'Paramètre latitude'}, 'longitude': {'type': 'string', 'description': 'Paramètre longitude'}}, 'required': ['latitude', 'longitude']}}]}]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T16:20:31.300746Z",
     "start_time": "2025-09-01T16:20:28.192903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.5-flash\", # Replace with your actual key\n",
    "    tools=tools_gemini\n",
    ")\n",
    "# Generate content\n",
    "message =\"donne une liste des transactions du redevable VDL-000030821?\"\n",
    "response = model.generate_content(message)\n",
    "\n",
    "results=[f\"la question initiale: {message}\"]\n",
    "tool_responses=[]\n",
    "# Print the result\n",
    "for part in response.candidates[0].content.parts:\n",
    "    # Vérifier si la partie est un appel de fonction\n",
    "    if hasattr(part, 'function_call'):\n",
    "        tool_call = part.function_call\n",
    "\n",
    "        # Obtenir le nom de la fonction et ses arguments\n",
    "        tool_name = tool_call.name\n",
    "        tool_args = tool_call.args\n",
    "\n",
    "        print(f\"Le modèle a demandé d'exécuter la fonction : {tool_name}\")\n",
    "        print(f\"Avec les arguments : {tool_args}\")\n",
    "        result = AgentTools().use_tool(tool_name,tool_args)\n",
    "\n",
    "        tool_responses.append(result)\n",
    "\n",
    "if tool_responses:\n",
    "    print(\"\\n-------------------------------------------------------------\")\n",
    "    print(\"Résultat des outils obtenu. On le renvoie au modèle...\")\n",
    "    print(\"-------------------------------------------------------------\")\n",
    "\n",
    "    # 1. Créez un objet de contenu pour le message initial de l'utilisateur\n",
    "    user_content = genai.protos.Content(\n",
    "        parts=[genai.protos.Part(text=message)],\n",
    "        role='user'\n",
    "    )\n",
    "\n",
    "    # 2. L'historique de la conversation commence par le message de l'utilisateur...\n",
    "    chat_history = [user_content]\n",
    "\n",
    "    # 3. ...suivi par la réponse du modèle qui contient l'appel de fonction...\n",
    "    chat_history.append(response.candidates[0].content)\n",
    "\n",
    "    # 4. ...suivi par la réponse de l'outil qui contient les résultats.\n",
    "    tool_content = genai.protos.Content(\n",
    "        parts=[genai.protos.Part(text=tool_responses[0])],\n",
    "        role='user'\n",
    "    )\n",
    "    chat_history.append(tool_content)\n",
    "\n",
    "    # Relancez generate_content avec l'historique complet pour obtenir la réponse finale\n",
    "    final_response = model.generate_content(chat_history)\n",
    "    print(\"\\n-------------------------------------------------------------\")\n",
    "    print(\"Réponse finale du modèle :\")\n",
    "    print(\"-------------------------------------------------------------\")\n",
    "    print(final_response.text)\n",
    "else:\n",
    "    print(\"\\n-------------------------------------------------------------\")\n",
    "    print(\"Le modèle a fourni une réponse textuelle directe :\")\n",
    "    print(\"-------------------------------------------------------------\")\n",
    "    print(response.text)\n"
   ],
   "id": "69bb548e0084c780",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle a demandé d'exécuter la fonction : f_get_data\n",
      "Avec les arguments : <proto.marshal.collections.maps.MapComposite object at 0x000001E4FEF46B90>\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Résultat des outils obtenu. On le renvoie au modèle...\n",
      "-------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------\n",
      "Réponse finale du modèle :\n",
      "-------------------------------------------------------------\n",
      "J'ai bien noté que le redevable VDL-000030821 a 2 créances ouvertes avec les références 152011989007 et 240006105142, toutes deux liées aux redevances de stationnement du 31/05/2022.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T14:59:47.686295Z",
     "start_time": "2025-09-01T14:59:46.074769Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Client' object has no attribute 'responses'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      2\u001B[39m prompt=Prompt(role,context,source,message)\n\u001B[32m      3\u001B[39m client = genai.Client(api_key=gemini_api_key)\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m result = \u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresponses\u001B[49m.generate(\n\u001B[32m      5\u001B[39m     model=\u001B[33m\"\u001B[39m\u001B[33mgemini-2.5-flash\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      6\u001B[39m     contents=\u001B[33m\"\u001B[39m\u001B[33mExplique brièvement comment fonctionne l\u001B[39m\u001B[33m'\u001B[39m\u001B[33mIA\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      7\u001B[39m     tools=tools\n\u001B[32m      8\u001B[39m )\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m#print(result)\u001B[39;00m\n\u001B[32m     10\u001B[39m k=\u001B[32m0\u001B[39m\n",
      "\u001B[31mAttributeError\u001B[39m: 'Client' object has no attribute 'responses'"
     ]
    }
   ],
   "execution_count": 17,
   "source": "",
   "id": "e865fbeaa8ab248a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bf92e6eac51c69df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
