{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-12T17:55:16.366017Z",
     "start_time": "2025-11-12T17:51:11.865591Z"
    }
   },
   "source": [
    "from pydantic import BaseModel, HttpUrl,EmailStr\n",
    "from docling.document_converter import DocumentConverter\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "\n",
    "\n",
    "converter = DocumentConverter()\n",
    "Model = \"gpt-5-nano\"\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "client= OpenAI(api_key=os.getenv(\"openai_key\"))\n",
    "\n",
    "class Source(BaseModel):\n",
    "    url: HttpUrl\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    summary: str\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    text: str\n",
    "    url: str\n",
    "\n",
    "class SearchResult(BaseModel):\n",
    "    answer: str\n",
    "    citations: List[Citation]\n",
    "\n",
    "domains = [\n",
    "    \"rijksoverheid.nl\",\n",
    "    \"tweedekamer.nl\",\n",
    "    \"cbs.nl\",\n",
    "]\n",
    "\n",
    "\n",
    "test_url=\"https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence\"\n",
    "\n",
    "source=Source(url=test_url)\n",
    "page_content = converter.convert(str(source.url))\n",
    "mk_content=page_content.document.export_to_markdown()\n",
    "print(mk_content)\n",
    "\n",
    "query = \"What are the current policies and regulations regarding AI implementation in Dutch government services, and what are the key requirements for public sector AI adoption?\"\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model=Model,\n",
    "    reasoning={\"effort\": \"medium\"},\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\",\n",
    "            \"filters\": {\n",
    "                \"allowed_domains\": domains,\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    tool_choice=\"auto\",\n",
    "    include=[\"web_search_call.action.sources\"],\n",
    "    input=query,\n",
    "    instructions=\"You are a policy research assistant for Dutch governmental agencies. You search official government websites to find relevant policy documents, regulations, and official information. For each piece of information in your answer, provide a citation that includes the specific text excerpt and the URL where it came from.\",\n",
    "    text_format=SearchResult,\n",
    ")\n",
    "\n",
    "result = response.output[-1].content[-1].parsed\n",
    "print(result.model_dump_json(indent=2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# EU AI Act: first regulation on artificial intelligence\n",
      "\n",
      "The use of artificial intelligence in the EU is regulated by the AI Act, the world's first comprehensive AI law. Find out how it  protects you.\n",
      "\n",
      "Published: 08-06-2023\n",
      "\n",
      "Last updated: 19-02-2025 - 17:46\n",
      "\n",
      "7 min read\n",
      "\n",
      "## Table of contents\n",
      "\n",
      "- AI regulation in Europe: the first comprehensive framework\n",
      "- What Parliament wanted in AI legislation\n",
      "- AI Act: different rules for different risk levels\n",
      "- Transparency requirements\n",
      "- Encouraging AI innovation and start-ups in Europe\n",
      "- Implementation\n",
      "- EU AI Act compliance timeline\n",
      "- More on the EU's digital measures\n",
      "\n",
      "This illustration of artificial intelligence has in fact been generated by AI\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "As part of its digital strategy, the EU wanted to regulate artificial intelligence (AI) to ensure better conditions for the development and use of this innovative technology. AI can create many benefits, such as better healthcare, safer and cleaner transport, more efficient manufacturing, and cheaper and more sustainable energy.\n",
      "\n",
      "## AI regulation in Europe: the first comprehensive framework\n",
      "\n",
      "In April 2021, the European Commission proposed the first EU artificial intelligence law, establishing a risk-based AI classification system. AI systems that can be used in different applications are analysed and classified according to the risk they pose to users. The different risk levels mean more or less AI compliance requirements.\n",
      "\n",
      "- Learn more about what artificial intelligence is and how it is used\n",
      "\n",
      "## What Parliament wanted in AI legislation\n",
      "\n",
      "Parliament's priority was to make sure that AI systems used in the EU are safe, transparent, traceable, non-discriminatory and environmentally friendly. AI systems should be overseen by people, rather than by automation, to prevent harmful outcomes.\n",
      "\n",
      "Parliament also wanted to establish a technology-neutral, uniform definition for AI that could be applied to future AI systems.\n",
      "\n",
      "- Learn more about Parliament's vision for AI's future\n",
      "\n",
      "## AI Act: different rules for different risk levels\n",
      "\n",
      "The new rules establish obligations for providers and users depending on the level of risk of AI risk qualification. While many AI systems pose minimal risk, they need to be assessed.\n",
      "\n",
      "### Unacceptable risk\n",
      "\n",
      "Banned AI applications in the EU include:\n",
      "\n",
      "- Cognitive behavioural manipulation of people or specific vulnerable groups: for example voice-activated toys that encourage dangerous behaviour in children\n",
      "- Social scoring AI: classifying people based on behaviour, socio-economic status or personal characteristics\n",
      "- Biometric identification and categorisation of people\n",
      "- Real-time and remote biometric identification systems, such as facial recognition in public spaces\n",
      "\n",
      "Some exceptions may be allowed for law enforcement purposes. \"Real-time\" remote biometric identification systems will be allowed in a limited number of serious cases, while \"post\" remote biometric identification systems, where identification occurs after a significant delay, will be allowed to prosecute serious crimes and only after court approval.\n",
      "\n",
      "### High risk\n",
      "\n",
      "AI systems that negatively affect safety or fundamental rights will be considered high risk and will be divided into two categories:\n",
      "\n",
      "1) AI systems that are used in products falling under the EU's product safety legislation. This includes toys, aviation, cars, medical devices and lifts.\n",
      "\n",
      "2) AI systems falling into specific areas that will have to be registered in an EU database:\n",
      "\n",
      "- Management and operation of critical infrastructure\n",
      "- Education and vocational training\n",
      "- Employment, worker management and access to self-employment\n",
      "- Access to and enjoyment of essential private services and public services and benefits\n",
      "- Law enforcement\n",
      "- Migration, asylum and border control management\n",
      "- Assistance in legal interpretation and application of the law.\n",
      "\n",
      "All high-risk AI systems will be assessed before being put on the market and also throughout their lifecycle. People will have the right to file complaints about AI systems to designated national authorities.\n",
      "\n",
      "## Transparency requirements\n",
      "\n",
      "Generative AI, like ChatGPT, will not be classified as high-risk, but will have to comply with transparency requirements and EU copyright law:\n",
      "\n",
      "- Disclosing that the content was generated by AI\n",
      "- Designing the model to prevent it from generating illegal content\n",
      "- Publishing summaries of copyrighted data used for training\n",
      "\n",
      "High-impact general-purpose AI models that might pose systemic risk, such as the more advanced AI model GPT-4, would have to undergo thorough evaluations and any serious incidents would have to be reported to the European Commission.\n",
      "\n",
      "Content that is either generated or modified with the help of AI - images, audio or video files (for example deepfakes) - need to be clearly labelled as AI generated so that users are aware when they come across such content.\n",
      "\n",
      "## Encouraging AI innovation and start-ups in Europe\n",
      "\n",
      "The law aims to support AI innovation and start-ups in Europe, allowing companies to develop and test general-purpose AI models before public release.\n",
      "\n",
      "That is why it requires that national authorities provide companies with a testing environment for AI that simulates conditions close to the real world. This will help small and medium-sized enterprises (SMEs) compete in the growing EU artificial intelligence market.\n",
      "\n",
      "## Implementation\n",
      "\n",
      "The Parliament has set up a working group to oversee the implementation and enforcement of the AI Act., MEPs want to make sure that the adopted AI rules contribute to the development of the digital sector in Europe.\n",
      "\n",
      "The group cooperates with the European Commission's EU AI office, which was set up to clarify key provisions of the act.\n",
      "\n",
      "## EU AI Act compliance timeline\n",
      "\n",
      "In June 2024, the EU adopted the world's first rules on AI. The Artificial Intelligence Act will be fully applicable 24 months after entry into force, but some parts will be applicable sooner:\n",
      "\n",
      "- The ban of AI systems posing unacceptable risks started to apply on 2 February 2025\n",
      "- Codes of practice will apply nine months after entry into force\n",
      "- Rules on general-purpose AI systems that need to comply with transparency requirements will apply 12 months after the entry into force\n",
      "\n",
      "High-risk systems will have more time to comply with the requirements as the obligations concerning them will become applicable 36 months after the entry into force.\n",
      "\n",
      "## More on the EU's digital measures\n",
      "\n",
      "- Cryptocurrency dangers and the benefits of EU legislation\n",
      "- Fighting cybercrime: new EU cybersecurity laws explained\n",
      "- Boosting data sharing in the EU: what are the benefits?\n",
      "- EU Digital Markets Act and Digital Services Act\n",
      "- Five ways the European Parliament wants to protect online gamers\n",
      "\n",
      "## Briefing\n",
      "\n",
      "- Artificial Intelligence Act\n",
      "- Q&amp;A: artificial intelligence Opens in a new window\n",
      "<!-- image -->\n",
      "\n",
      "## Share this article on:\n",
      "\n",
      "- Share this page on Facebook\n",
      "<!-- image -->\n",
      "- Share this page on X\n",
      "<!-- image -->\n",
      "- Share this page on LinkedIn\n",
      "<!-- image -->\n",
      "- Share this page on WhatsApp\n",
      "<!-- image -->\n",
      "\n",
      "- Sign up for mail updates\n",
      "- PDF version\n",
      "\n",
      "## Topics\n",
      "\n",
      "View menu: News\n",
      "\n",
      "### Parliament in your country\n",
      "\n",
      "- Open in a new page London\n",
      "- Open in a new page Dublin\n",
      "- Open in a new page Valletta\n",
      "- Open in a new page Washington\n",
      "\n",
      "### Tools\n",
      "\n",
      "- Open in a new page Legislative Observatory\n",
      "- Multimedia Centre\n",
      "- Open in a new page EbS\n",
      "\n",
      "### President of the European Parliament\n",
      "\n",
      "- Open in a new page Presidency\n",
      "\n",
      "## European Parliament\n",
      "\n",
      "View menu: European Parliament\n",
      "\n",
      "- News\n",
      "- Topics\n",
      "- MEPs\n",
      "- About Parliament\n",
      "- Plenary\n",
      "- Committees\n",
      "- Delegations\n",
      "- EU budget\n",
      "\n",
      "## The Parliament on social media\n",
      "\n",
      "- Check out Parliament on Facebook\n",
      "- Check out Parliament on X\n",
      "- Check out Parliament on Flickr\n",
      "- Check out Parliament on LinkedIn\n",
      "- Check out Parliament on YouTube\n",
      "- Check out Parliament on Instagram\n",
      "- Check out Parliament on Pinterest\n",
      "- Check out Parliament on Reddit\n",
      "\n",
      "## Information links\n",
      "\n",
      "- Contact\n",
      "- RSS\n",
      "- Sitemap\n",
      "- Legal notice\n",
      "- Privacy policy\n",
      "- Accessibility\n",
      "{\n",
      "  \"answer\": \"Here is a concise overview of the current policy and regulatory landscape for AI in Dutch government services, with key requirements for public sector adoption, based on official sources up to November 12, 2025.\\n\\n1) Government-wide vision and governance for AI (generative AI) \\n- The Netherlands has an overheidsbrede visie op generatieve AI. Core principles include that Generatieve AI in Nederland should be developed and applied safely, and that it should serve public values and welfare. The vision also outlines six actielijnen to move from vision to action. Direct quotes: \\\"Generatieve AI in Nederland: Wordt op een veilige manier ontwikkeld en toegepast.\\\" and \\\"Door samen te werken... 6 actielijnen\\\". Source: Kabinet presenteert visie op generatieve AI (Jan 18, 2024). URL: https://www.rijksoverheid.nl/actueel/nieuws/2024/01/18/kabinet-presenteert-visie-op-generatieve-ai. Excerpt: “Generatieve AI in Nederland: Wordt op een veilige manier ontwikkeld en toegepast.”; “we... presenteert in deze visie 6 actielijnen.” — [turn5view0]. \\n- Vier uitgangspunten vormen de norm voor Generatieve AI: veiligheid, rechtvaardigheid, menselijke autonomie en duurzaamheid/welvaart. Source: Kabinet Present e visie (Jan 18, 2024). Excerpt: “Generatieve AI in Nederland: ... Wordt op een veilige manier ontwikkeld en toegepast … Dient het menselijk welzijn en de menselijke autonomie … Draagt bij aan duurzaamheid en onze welvaart.” — [turn5view0]. \\n- De visie benadrukt dat AI-bouwsteenkwaliteit (zoals open standaarden en Europese toepassingen) en samenwerking binnen de overheid centraal staan, met realisering via 6 actielijnen. Source: Kabinet presenteert visie op generatieve AI (Jan 2024). Excerpt: “Van visie naar actie… 6 actielijnen.” — [turn5view0]. \\n\\n2) Overheidsbreed standpunt en implementatie-kader (2025) \\n- In april 2025 heeft het kabinet het Overheidsbreed standpunt ingevoerd voor de inzet van generatieve AI bij de overheid, inclusief regels voor samenwerking en risicoanalyse, en aanmoediging van Europese/open-source oplossingen. Critical quotes: “Het kabinet heeft nieuwe spelregels afgesproken met gemeenten, provincies, waterschappen en uitvoeringsorganisaties over het gebruik van generatieve AI… Ambtenaren krijgen meer ruimte om generatieve AI te gebruiken… Hierbij moeten zij zich wel aan voorwaarden houden.” en “daarbij wordt aangemoedigd gebruik te maken van in Europa ontwikkelde toepassingen en open-source oplossingen.” — [turn3view0]. URL: https://www.rijksoverheid.nl/actueel/nieuws/2025/04/22/overheid-verruimt-standpunt-inzet-generatieve-ai. \\n- De standpunten gaan samen met een praktische handreiking en concrete handvatten voor Rijks- en decentrale overheden (handreiking voor verantwoorde inzet van AI). Quote: “Handreiking… technologische, organisatorische, ethische en juridische randvoorwaarden” — [turn12view0]. URL: https://www.rijksoverheid.nl/documenten/rapporten/2025/04/16/overheidsbrede-handreiking-generatieve-ai. \\n- De aanbiedingsbrief bij het standpunt biedt Kamerdebat en verduidelijkt de standpunten en bijlagen (Overheidsbreed standpunt). Quote: “Staatssecretaris Szabó... biedt de Tweede Kamer het overheidsbrede standpunt voor de inzet van Generatieve AI bij de overheid aan.” — [turn13view0]. URL: https://www.rijksoverheid.nl/documenten/kamerstukken/2025/04/22/kamerbrief-overheidsbreed-standpunt-inzet-generatieve-ai. \\n- Practical examples of responsible AI use in government mentioned in the April 2025 update: e.g., province Zuid-Holland’s PZH assistant and the Goes chatbot Guus (source: turn3view0). URL: https://www.rijksoverheid.nl/actueel/nieuws/2025/04/22/overheid-verruimt-standpunt-inzet-generatieve-ai.\\n\\n3) EU-wide AI Regulation (AI Act) and national alignment \\n- EU’s AI Act is in force in a phased manner; from 2 February 2025 certain prohibitions apply EU-wide (e.g., social scoring, emotion recognition in work/education, etc.). This provides a baseline of requirements and prohibitions for AI deployments in the public sector. Source: Europese verboden op ongewenste AI-toepassingen ingegaan (Feb 3, 2025). Excerpt: “Vanaf 2 februari 2025 gelden in de gehele EU diverse verboden op ongewenste toepassingen van AI.” and “bepalingen op verboden AI” / “hoog-risico AI-toepassingen… en transparantie” timelines. URL: https://www.rijksoverheid.nl/actueel/nieuws/2025/02/03/europese-verboden-op-ongewenste-ai-toepassingen-ingegaan. \\n- The Netherlands participates in EU-wide governance and supports alignment with EU rules; the Paris AI summit report notes AI as a strategic tech and mentions the AI-Verordening (AI Act) that has been in effect since 2024 with phased application. Quote: “Sinds de zomer van 2024 geldt in de Europese Unie bovendien de AI-verordening.” — [turn7view0]. URL: https://www.rijksoverheid.nl/actueel/nieuws/2025/02/06/kabinetsdelegatie-naar-internationale-top-over-ai-in-parijs. \\n- The timeline for the AI Act phasing includes: 2 Feb 2025 (prohibitions), 2 Aug 2025 (general-purpose AI), 2 Aug 2026 (high-risk AI), 2 Aug 2027 (high-risk AI products), etc. Source: turn4view0. Excerpt: “2 februari 2025: bepalingen op verboden AI; 2 augustus 2025: eisen voor AI-modellen voor algemene doeleinden … 2 augustus 2026: eisen voor hoog-risico AI-toepassingen en transparantie… 2 augustus 2027: eisen voor hoog-risico AI-producten.” URL: https://www.rijksoverheid.nl/actueel/nieuws/2025/02/03/europese-verboden-op-ongewenste-ai-toepassingen-ingegaan.\\n\\n4) Public-sector governance and local deployment considerations\\n- There is a push to allow the public sector to exploit generative AI more broadly while ensuring governance and accountability; and a push to develop AI tools within Europe/open-source ecosystems. Quote: “Generatieve AI biedt volop kansen… Chatbot Guus geeft antwoord… De chatbot gebruikt uitsluitend vooraf vastgelegde bronnen.” — [turn3view0]. URL: https://www.rijksoverheid.nl/actueel/nieuws/2025/04/22/overheid-verruimt-standpunt-inzet-generatieve-ai. \\n- There is emphasis on local data sovereignty and potential to run AI models locally; a Kamerbrief explicitly recognizes the motie to explore local-draai AI-modellen bij de overheid (AI models designed to run locally). Quote: “de motie Six Dijkstra … onderzoeken lokaal draaien AI-modellen bij de overheid.” — [turn8view0]. URL: https://www.rijksoverheid.nl/documenten/kamerstukken/2025/03/07/kamerbrief-appreciatie-motie-six-dijkstra-over-ondernemen-lokaal-draaien-ai-modellen-bij-de-overheid. \\n- The Netherlands is launching the National Data Strategy and AI-as-a-priority within the Dutch Digitaliseringsstrategie (NDS), including “kansen van AI verantwoord benutten” as a priority in the NDS-raad. Quote: “3. kansen van AI verantwoord benutten” (priority in NDS-raad). Source: NDS-raad van start: versnelling digitalisering overheid (Sept 2, 2025). URL: https://www.rijksoverheid.nl/actueel/nieuws/2025/09/02/nds-raad-van-start-versnelling-digitalisering-overheid. \\n- The AI policy for public sector emphasizes building capacity and literacy among civil servants (training, education) as part of the NDS and the government agenda. Source: turn6view0 lines 21-23 (the NDS-raad) and lines 23-25. URL: https://www.rijksoverheid.nl/actueel/nieuws/2025/09/02/nds-raad-van-start-versnelling-digitalisering-overheid. \\n\\n5) Data protection and rights considerations in AI deployments\\n- In parallel with AI policy, the Kamerstukken discuss adherence to the GDPR/AVG and data protection in AI deployment; references to AVG compliance and the need to ensure “bescherming persoonsgegevens en digitale grondrechten.” Source: Kamerstukken on AVG and data protection for AI. Excerpt: “Bescherming persoonsgegevens en digitale grondrechten …” — [turn10view0]. URL: https://www.tweedekamer.nl/kamerstukken/brieven_regering/detail?did=2024D27797&id=2024Z11580. \\n- The 2024-2025 policy packages also emphasize risk governance and due diligence, with focus on non-discrimination, privacy, and transparency (e.g., Rijks AI Validatieteam to assess AI applications for non-discrimination). Source: turn5view0 lines 28-29. URL: https://www.rijksoverheid.nl/actueel/nieuws/2024/01/18/kabinet-presenteert-visie-op-generatieve-ai.\\n\\n6) Practical implications and examples for government service delivery\\n- Actual examples in use include internal assistants and public-facing chatbot Guus that rely on predefined sources; indicates the approach of safe, controlled AI deployments in public service delivery. Source: turn3view0 lines 19-21. URL: https://www.rijksoverheid.nl/actueel/nieuws/2025/04/22/overheid-verruimt-standpunt-inzet-generatieve-ai. \\n\\nIf you’d like, I can tailor this to a specific ministry or service (e.g., permits, citizen inquiries, or social services) and map which policy elements apply and which translations into procurement or governance processes would be most relevant. I can also pull exact quotes and page-level citations for a formal briefing or policy memo. \\n\\nCitations with exact text excerpts and URLs used above:\\n- Kabinet presenteert visie op generatieve AI (Jan 18, 2024): Generatieve AI in Nederland: Wordt op een veilige manier ontwikkeld en toegepast; 6 actielijnen; Vier uitgangspunten. URL: https://www.rijksoverheid.nl/actueel/nieuws/2024/01/18/kabinet-presenteert-visie-op-generatieve-ai. Excerpts: “Generatieve AI in Nederland: Wordt op een veilige manier ontwikkeld en toegepast.”; “het presenteren van 6 actielijnen”; “uitgangspunten” — turn5view0. \\n- Overheid verruimt standpunt inzet generatieve AI (Apr 22, 2025): Nieuwe spelregels; risicoanalyses; betrouwbare modellen; Europese/open-source oplossingen. URL: https://www.rijksoverheid.nl/actueel/nieuws/2025/04/22/overheid-verruimt-standpunt-inzet-generatieve-ai. Excerpts: “Het kabinet heeft nieuwe spelregels afgesproken… Ambtenaren krijgen meer ruimte…”; “duidelijke risicoanalyses en het gebruik van betrouwbare generatieve AI-modellen… Europa… open-source oplossingen.” — turn3view0.\\n- Overheidsbrede handreiking (Jan 30, 2025): randvoorwaarden (technologisch, organisatorisch, ethisch, juridisch). URL: https://www.rijksoverheid.nl/documenten/rapporten/2025/04/16/overheidsbrede-handreiking-generatieve-ai. Excerpt: “randvoorwaarden die van meerwaarde zijn om als overheidsorganisatie tot de verantwoorde inzet van generatieve AI te komen.” — turn12view0.\\n- Overheidsbreed standpunt (Apr 22, 2025) Kamerstuk: Aanbiedingsbrief; standpunt; 6 actielijnen. URL: turn13view0 (Kamerstuk); turn3view0 (standpunt). Excerpts: “bieden het overheidsbreed standpunt voor de inzet van generatieve AI… bij de overheid”; “handreiking praktisch ondersteunend.” — turn13view0; turn12view0.\\n- EU AI Act – verboden en tijdlijnen (Feb 3, 2025): “Vanaf 2 februari 2025 gelden in de gehele EU diverse verboden op ongewenste AI-toepassingen.”; “2 februari 2025: bepalingen op verboden AI; 2 augustus 2025: eisen voor AI-modellen …”; URL: https://www.rijksoverheid.nl/actueel/nieuws/2025/02/03/europese-verboden-op-ongewenste-ai-toepassingen-ingegaan. Excerpt: lines 12-15; 22-26 — turn4view0.\\n- AI in Parijs en AI Act alignment (Feb 6, 2025): AI Act als EU-regelgeving; URL: turn7view0.\\n- Lokaal draaien van AI-modellen (Mar 7, 2025): motie Six Dijkstra; lokaal draaien AI-modellen bij de overheid. URL: turn8view0.\\n- NDS en AI-kansen (Sept 2, 2025): “kansen van AI verantwoord benutten” als prioriteit. URL: turn6view0.\\n- Kansen van Generatieve AI in de publieke sector (Apr 18, 2025): Kamerantwoorden; productivity. URL: turn14view0.\\n- AVG/AVG-compliance en data protectie (AVG–privacy) in AI deployments (Kamerstuk) – URL: turn10view0.\\n- Voorbeeld AI-inzichten en publieke dienstverlening (Chatbot Guus) (Apr 22, 2025): turn3view0.\",\n",
      "  \"citations\": [\n",
      "    {\n",
      "      \"text\": \"Generatieve AI in Nederland: Wordt op een veilige manier ontwikkeld en toegepast.\",\n",
      "      \"url\": \"https://www.rijksoverheid.nl/actueel/nieuws/2024/01/18/kabinet-presenteert-visie-op-generatieve-ai\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"6 actielijnen\",\n",
      "      \"url\": \"https://www.rijksoverheid.nl/actueel/nieuws/2024/01/18/kabinet-presenteert-visie-op-generatieve-ai\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Vier uitgangspunten\",\n",
      "      \"url\": \"https://www.rijksoverheid.nl/actueel/nieuws/2024/01/18/kabinet-presenteert-visie-op-generatieve-ai\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Het kabinet heeft nieuwe spelregels afgesproken met gemeenten, provincies, waterschappen en uitvoeringsorganisaties over het gebruik van generatieve AI... Ambtenaren krijgen meer ruimte om generatieve AI te gebruiken in hun werk, bijvoorbeeld om vergunningsaanvragen te versnellen, vragen van burgers en ondernemers sneller te beantwoorden of om efficiënter besluiten te nemen.\",\n",
      "      \"url\": \"https://www.rijksoverheid.nl/actueel/nieuws/2025/04/22/overheid-verruimt-standpunt-inzet-generatieve-ai\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"daarbij wordt aangemoedigd gebruik te maken van in Europa ontwikkelde toepassingen en open-source oplossingen\",\n",
      "      \"url\": \"https://www.rijksoverheid.nl/actueel/nieuws/2025/04/22/overheid-verruimt-standpunt-inzet-generatieve-ai\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"randvoorwaarden die van meerwaarde zijn om als overheidsorganisatie tot de verantwoorde inzet van generatieve AI te komen\",\n",
      "      \"url\": \"https://www.rijksoverheid.nl/documenten/rapporten/2025/04/16/overheidsbrede-handreiking-generatieve-ai\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Overheidsbrede handreiking voor de verantwoorde inzet van generatieve AI\",\n",
      "      \"url\": \"https://www.rijksoverheid.nl/documenten/rapporten/2025/04/16/overheidsbrede-handreiking-generatieve-ai\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Aanbiedingsbrief bij Overheidsbreed standpunt voor de inzet van generatieve AI\",\n",
      "      \"url\": \"https://www.rijksoverheid.nl/documenten/kamerstukken/2025/04/22/kamerbrief-overheidsbreed-standpunt-inzet-generatieve-ai\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"2 februari 2025: bepalingen op verboden AI; 2 augustus 2025: eisen voor AI-modellen voor algemene doeleinden; 2 augustus 2026: eisen voor hoog-risico AI-toepassingen en transparantie; 2 augustus 2027: eisen voor hoog-risico AI-producten\",\n",
      "      \"url\": \"https://www.rijksoverheid.nl/actueel/nieuws/2025/02/03/europese-verboden-op-ongewenste-ai-toepassingen-ingegaan\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tallar\\Documents\\PROJETS\\GenAI\\venv\\Lib\\site-packages\\pydantic\\main.py:463: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `literal['function']` - serialized value may not be as expected [input_value='web_search', input_type=str])\n",
      "  PydanticSerializationUnexpectedValue(Expected `FileSearchTool` - serialized value may not be as expected [input_value=FunctionTool(name=None, p...None, 'timezone': None}), input_type=FunctionTool])\n",
      "  PydanticSerializationUnexpectedValue(Expected `WebSearchTool` - serialized value may not be as expected [input_value=FunctionTool(name=None, p...None, 'timezone': None}), input_type=FunctionTool])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ComputerTool` - serialized value may not be as expected [input_value=FunctionTool(name=None, p...None, 'timezone': None}), input_type=FunctionTool])\n",
      "  PydanticSerializationUnexpectedValue(Expected `Mcp` - serialized value may not be as expected [input_value=FunctionTool(name=None, p...None, 'timezone': None}), input_type=FunctionTool])\n",
      "  PydanticSerializationUnexpectedValue(Expected `CodeInterpreter` - serialized value may not be as expected [input_value=FunctionTool(name=None, p...None, 'timezone': None}), input_type=FunctionTool])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ImageGeneration` - serialized value may not be as expected [input_value=FunctionTool(name=None, p...None, 'timezone': None}), input_type=FunctionTool])\n",
      "  PydanticSerializationUnexpectedValue(Expected `LocalShell` - serialized value may not be as expected [input_value=FunctionTool(name=None, p...None, 'timezone': None}), input_type=FunctionTool])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
